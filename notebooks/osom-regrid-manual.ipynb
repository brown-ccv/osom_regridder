{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ec1d48-ce27-4d19-807f-d6c71b84f90e",
   "metadata": {},
   "source": [
    "# Manually Regridding OSOM Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e69453f-7917-4e3b-b6ce-19a7ff6ac090",
   "metadata": {},
   "source": [
    "The OSOM data (model output and bathymetry) uses it's own internal grid for modelling. To have a usable output, the data needs to be transformed into a more \"normal\" grid that can be georeferenced and tiled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9079da-c731-4159-a8e5-a10bc98fbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries used in Regridding\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "# For Display\n",
    "import datetime\n",
    "\n",
    "# Image Creation (demo)\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db62d9d-37de-48b3-a68c-1e88b4dbf5f6",
   "metadata": {},
   "source": [
    "File paths for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442ac6ca-43f8-4fb6-808f-f0038629f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define useful parameters\n",
    "grid_path = \"/oscar/data/epscor/OSOM/input/ROMS_forcing_files/grid/osom_grid4_mindep_smlp_mod10.nc\"\n",
    "data_path = \"/oscar/data/epscor/OSOM/output/OSOM_v2/2022/\"\n",
    "data_filename = \"ocean_his_6210.nc\"\n",
    "data_varname = (\n",
    "    \"temp\"  # variable names include temp, salt, zeta, ubar_eastward, ubar_westward\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eaf24a-da30-4070-be45-83b7cfa299f1",
   "metadata": {},
   "source": [
    "## Import OSOM Grid & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b81b2253-0852-4286-b153-73066b24332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OSOM Grid Data\n",
    "osom_grid = nc.Dataset(grid_path)\n",
    "\n",
    "lon = osom_grid.variables[\"lon_rho\"][:]\n",
    "lat = osom_grid.variables[\"lat_rho\"][:]\n",
    "mask = osom_grid.variables[\"mask_rho\"][:]\n",
    "bathy = osom_grid.variables[\"h\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a30b4d-bd65-406e-b302-7cc29af7ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data File\n",
    "ds = nc.Dataset(data_path + data_filename)\n",
    "#\n",
    "time = ds.variables[\"ocean_time\"][:]\n",
    "data = ds.variables[data_varname][\n",
    "    :, -1, :, :\n",
    "]  # for surface layers: [:,-1,:,:]; for bottom layers: [:,0,:,:]\n",
    "\n",
    "\n",
    "# Function to translate OSOM date (calculated as consecutive days from 1 Jan 2005)\n",
    "# and convert it to a generic date in time in a format that is useful\n",
    "# for plotting.\n",
    "def get_date(idx):\n",
    "    date = datetime.datetime(2005, 1, 1) + datetime.timedelta(seconds=time[idx])\n",
    "    date_string = date.strftime(\n",
    "        \"%d %b %Y %H:%M\"\n",
    "    )  # https://strftime.org/ for a cheat sheet\n",
    "    return date_string\n",
    "\n",
    "\n",
    "timepoint = 1\n",
    "time_string = get_date(timepoint)\n",
    "data_at_timepoint = data[timepoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851356a-b0cd-4dac-bbb5-a69094c5213a",
   "metadata": {},
   "source": [
    "The model data that OSOM outputs eixsts on an almost trapezoidial grid. That means that each OSOM grid cell is a lot smaller (in a lat/lon) sense the more north you go. Given this, here's the basic algorith to perform this transformation.\n",
    "\n",
    "1. Find the lat / lon bounds of the dataset.\n",
    "2. Determine the pixel count for the output image. (OSOM data comes in 1000x1100, but for this transformed data, there's going to be a lot more dead space, so the pixel count should probably be larger.)\n",
    "3. Create a 2D array of the size determined in step 2.\n",
    "4. For each element in this array:\n",
    "   1. Determine the lat/lon coordinate point of this element.\n",
    "   2. Use the grid to determine the xi/eta coordinates of that point (the internal grid system used by the OSOM dataset).\n",
    "   3. If a data point is found, place the model value at current element of the output image.\n",
    "   4. Otherwise, place a null value at that element.\n",
    "\n",
    "Because of the shifting scale of the OSOM data points, the process of \"selecting the correct model value\" will probably require averaging across several OSOM data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e58cd2-d05b-4f4c-8131-a9e555c55344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounds: 40.51 to 42.17 (lat) -72.67 to -69.99 (lon)\n"
     ]
    }
   ],
   "source": [
    "# Compute Lat / Lon bounds\n",
    "\n",
    "lat_min = np.min(lat)\n",
    "lat_max = np.max(lat)\n",
    "lon_min = np.min(lon)\n",
    "lon_max = np.max(lon)\n",
    "\n",
    "lat_range = lat_max - lat_min\n",
    "lon_range = lon_max - lon_min\n",
    "\n",
    "print(\n",
    "    f\"Bounds: {round(lat_min, 2)} to {round(lat_max, 2)} (lat) {round(lon_min, 2)} to {round(lon_max, 2)} (lon)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "117701ee-8308-45f8-9339-b5c175a2e3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6670863969781493 2.680264108770743\n"
     ]
    }
   ],
   "source": [
    "# Establish output raster size\n",
    "\n",
    "print(lat_range, lon_range)\n",
    "\n",
    "output_dim_x = 26 * 100  # Small values for test\n",
    "output_dim_y = 16 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa82afd6-d38d-4ab0-8e3a-d58eec346981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model data for output point\n",
    "\n",
    "lat_cell_size = lat_range / output_dim_y\n",
    "lon_cell_size = lon_range / output_dim_x\n",
    "\n",
    "\n",
    "def get_coordinates_for_point(x, y):\n",
    "    cell_lon_min = (x * lon_cell_size) + lon_min\n",
    "    cell_lon_max = ((x + 1) * lon_cell_size) + lon_min\n",
    "    cell_lat_min = (y * lat_cell_size) + lat_min\n",
    "    cell_lat_max = ((y + 1) * lat_cell_size) + lat_min\n",
    "    return (cell_lon_min, cell_lon_max, cell_lat_min, cell_lat_max)\n",
    "\n",
    "\n",
    "def get_data_for_points(x_mask, y_mask, dataset):\n",
    "    # Note (AM): This is a method that's a little flawed right now. This will collect\n",
    "    # all points enclosed by a lat/lon region. For low density regriddings, it's\n",
    "    # totally okay, but for higher density ones it's a little worse. For example, it's\n",
    "    # possible to imagine a dataset pixel that encloses entirely a regridding pixel, which\n",
    "    # would be skipped under the current algorithm. In effect, this only detects the *edges*\n",
    "    # of dataset pixels, not the pixels themselves.\n",
    "    collected_data = []\n",
    "    for i in range(len(x_mask)):\n",
    "        data = dataset[x_mask[i]][y_mask[i]]\n",
    "        collected_data.append(data)\n",
    "    return collected_data\n",
    "\n",
    "\n",
    "def get_model_data_at_point(x, y, grid_lon, grid_lat, dataset):\n",
    "    cell_lon_min, cell_lon_max, cell_lat_min, cell_lat_max = get_coordinates_for_point(\n",
    "        x, y\n",
    "    )\n",
    "    lon_mask = (grid_lon > cell_lon_min) & (grid_lon < cell_lon_max)\n",
    "    lat_mask = (grid_lat > cell_lat_min) & (grid_lat < cell_lat_max)\n",
    "    x_mask, y_mask = np.where(lon_mask & lat_mask)\n",
    "    bounded_points = get_data_for_points(x_mask, y_mask, dataset)\n",
    "    if len(bounded_points) >= 1:\n",
    "        averaged_points = np.average(bounded_points)\n",
    "        return averaged_points\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b6d35-7c59-48f7-b56e-6479e2d9d343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 2600\n",
      "1 / 2600\n",
      "2 / 2600\n",
      "3 / 2600\n",
      "4 / 2600\n",
      "5 / 2600\n"
     ]
    }
   ],
   "source": [
    "def populate_regrid(size_x, size_y, grid_lon, grid_lat, dataset):\n",
    "    regrid = np.empty((size_x, size_y))\n",
    "    regrid.fill(np.nan)\n",
    "    for x in range(size_x):\n",
    "        print(x, \"/\", size_x)\n",
    "        for y in range(size_y):\n",
    "            regrid[x][y] = get_model_data_at_point(x, y, grid_lon, grid_lat, dataset)\n",
    "    return regrid\n",
    "\n",
    "\n",
    "regridded = populate_regrid(output_dim_x, output_dim_y, lon, lat, data_at_timepoint)\n",
    "# print(regridded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a6a49c-dbae-4407-b633-0278cc0cea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.unique(regridded[~np.isnan(regridded)])\n",
    "output_min = np.min(values)\n",
    "output_max = np.max(values)\n",
    "\n",
    "\n",
    "def normalize(v, v_scale_min, v_scale_max, o_scale_min, o_scale_max):\n",
    "    standard_normalization = (v - v_scale_min) / (v_scale_max - v_scale_min)\n",
    "    return ((o_scale_max - o_scale_min) * standard_normalization) + o_scale_min\n",
    "\n",
    "\n",
    "def create_image(dataset):\n",
    "    # Create a base transparent image\n",
    "    image = Image.new(\n",
    "        mode=\"RGBA\", size=(output_dim_x, output_dim_y), color=(0, 0, 0, 0)\n",
    "    )\n",
    "    for x in range(output_dim_x):\n",
    "        for y in range(output_dim_y):\n",
    "            value = dataset[x][y]\n",
    "            if not np.isnan(value):\n",
    "                color_as_value = int(normalize(value, output_min, output_max, 0, 255))\n",
    "                image.putpixel(\n",
    "                    (x, output_dim_y - 1 - y), (color_as_value, 0, color_as_value, 255)\n",
    "                )\n",
    "    return image\n",
    "\n",
    "\n",
    "im = create_image(regridded)\n",
    "display(im)\n",
    "imshow(np.asarray(im))\n",
    "im.save(f\"{output_dim_x}x{output_dim_y}-databay.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c62104-74d9-44e1-a295-5204fe06c6d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a82b963-eb06-42d4-b571-649e40d60524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
